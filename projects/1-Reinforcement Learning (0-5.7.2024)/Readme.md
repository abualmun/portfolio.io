# ğŸ¤– RoboFly: Reinforcement Learning Agent for Flappy Bird Clone ğŸª°

Welcome to **RoboFly** â€“ my first hands-on Reinforcement Learning project after completing the Stanford Machine Learning Specialization on Coursera ğŸ“. I was inspired to immediately apply what I learned, and this fun (yet frustrating ğŸ˜…) Flappy Bird-style game provided the perfect testbed!

## ğŸ¯ Goal

Train an RL agent to play RoboFly, improving performance through trial and error inside a real game engine â€” **not just a simulated environment**.

## ğŸ§  Reinforcement Learning Approach

After diving into RL, I was fascinated by the core idea:
> Let a model learn *by itself* through **rewards and punishments** in a simulated environment.

### ğŸ’¡ Why RoboFly?

- Simple scoring system makes performance easy to measure.
- Game authored by @AhmedElnour123, meaning clean and modifiable code ğŸ’ª.
- Lightweight game logic â€” perfect for fast training and testing loops.

### ğŸ”„ Agent Workflow

1. ğŸ”Œ **Integration**: Used **socket communication** to connect a `TensorFlow` model in Python with a real-time scene in the **Godot 4.2** engine.
2. ğŸ•¹ï¸ **Control loop**:
   - Python sends an action (e.g., flap or don't).
   - Godot executes the action and returns updated game state.
   - Agent receives rewards (surviving, scoring) or punishments (crashing).
3. â™»ï¸ Repeat millions of times â€” all inside a real game, not a mock simulation.

## âš™ï¸ Tools & Tech

- ğŸ§  TensorFlow (Python) â€” RL logic and training.
- ğŸ•¹ï¸ Godot Engine 4.2 â€” real-time game environment.
- ğŸ”— Socket server â€” communication between agent and game.
- ğŸ§ª Custom reward function â€” based on survival and score.

## ğŸ“ˆ Training Journey

- ğŸš€ Best score achieved by the trained agent: **266**
- ğŸ§ª One early training attempt failed after **11,000+ episodes** with zero progress ğŸ˜‚
- ğŸ‘¨ğŸ¾â€ğŸ”¬ Later iterations improved significantly, thanks to:
  - Better model structure
  - Smarter reward shaping
  - More optimized state information exchange

## ğŸ¤” Lessons Learned

- Game randomness might require longer training than expected ğŸ²
- Socket latency could bottleneck real-time decision making ğŸ¢
- Model design has a major impact on learning capability ğŸ§ 

## ğŸ Final Thoughts

This project was a **huge motivational boost** for my AI journey. It was challenging but so rewarding to watch a self-taught agent slowly master a game I personally enjoy (and sometimes hate ğŸ¤£). More to come, inshallah! ğŸ™ğŸ¾

---

Made with passion â¤ï¸ by Munther | @Munther474

